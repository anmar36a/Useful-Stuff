{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj+N74AJ1SmEGwaHHVrWln"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The notebook creates a mp3 audio file with a summary in Spanish of the news and\n",
        "the weather for the given regions. It costs around 0,1€ using OpenAI's API.\n",
        "\n",
        "It follows the guide at https://www.datacamp.com/code-along/working-with-apis-in-python\n",
        "'''"
      ],
      "metadata": {
        "id": "TELUXDTNkDXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "bc261nTbl29k"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "API_KEY_NEWSAPI = userdata.get('API_KEY_NEWSAPI')\n",
        "API_KEY_METEOSOURCE = userdata.get('API_KEY_METEOSOURCE')\n",
        "API_KEY_OPENAI = userdata.get('API_KEY_OPENAI')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "eG9s3_VwqHRv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COUNTRY_FOR_NEWS = \"us\" # Spain is not supported\n",
        "CITY_FOR_WEATHER = \"Barcelona\""
      ],
      "metadata": {
        "id": "nt6JBdS0kNXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Newsletter info"
      ],
      "metadata": {
        "id": "PxGBX2wpOEMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare API request for Newsapi\n",
        "news_api_url_parameters = {\n",
        "    'apiKey': API_KEY_NEWSAPI,\n",
        "    'country': COUNTRY_FOR_NEWS\n",
        "}\n",
        "# It doesn't have support for any spanish newspaper. Gnews doesn't either."
      ],
      "metadata": {
        "id": "qFrKBKsYrEUd"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get headline articles for a given country from Newsapi\n",
        "news_response = requests.get('https://newsapi.org/v2/top-headlines',\n",
        "                             news_api_url_parameters)\n",
        "\n",
        "if news_response.status_code == 200:\n",
        "  news_response_data = news_response.json()\n",
        "\n",
        "  headline_articles = [\n",
        "      {'title': article['title'],\n",
        "       'description': article['description']}\n",
        "      for article in news_response_data['articles'][:10]\n",
        "  ]\n",
        "\n",
        "  print(headline_articles[0])\n",
        "else:\n",
        "  print(news_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG3xELklriq9",
        "outputId": "3a1c5440-8160-42eb-cb1d-0aa0aeee068d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'A ‘worst-case’ scenario: How giant insurance losses from L.A. fires could affect all Californians - San Francisco Chronicle', 'description': \"The enormous wildfires burning through Los Angeles County are likely to worsen California's already bad insurance crisis, just as reforms were taking effect.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare API request for Meteosource to find id of a place\n",
        "meteosource_api_headers = {\n",
        "    'X-API-Key': API_KEY_METEOSOURCE\n",
        "}\n",
        "\n",
        "meteosource_findplaces_url_parameters = {\n",
        "    'text': CITY_FOR_WEATHER\n",
        "}"
      ],
      "metadata": {
        "id": "e2NX9xpsv-u2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get id of the place where we want to know the forecast\n",
        "meteosource_response = requests.get(\n",
        "    'https://www.meteosource.com/api/v1/free/find_places',\n",
        "    params = meteosource_findplaces_url_parameters,\n",
        "    headers = meteosource_api_headers)\n",
        "\n",
        "if meteosource_response.status_code == 200:\n",
        "  meteosource_response_data = meteosource_response.json()\n",
        "\n",
        "  place_id = meteosource_response_data[0]['place_id']\n",
        "  print(place_id)\n",
        "\n",
        "else:\n",
        "  print(meteosource_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW6HOsudxPdn",
        "outputId": "1668f164-7fd2-4541-9ce2-3e3b94a085ba"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "barcelona\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare API request for Meteosource to get the weather\n",
        "meteosource_point_url_parameters = {\n",
        "    'place_id': place_id,\n",
        "    'sections': 'daily',\n",
        "}"
      ],
      "metadata": {
        "id": "ig0FDUzlz-BJ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get id of the place where we want to know the forecast\n",
        "meteosource_response = requests.get(\n",
        "    'https://www.meteosource.com/api/v1/free/point',\n",
        "    params = meteosource_point_url_parameters,\n",
        "    headers = meteosource_api_headers)\n",
        "\n",
        "if meteosource_response.status_code == 200:\n",
        "  meteosource_response_data = meteosource_response.json()\n",
        "\n",
        "  weather_forecast = meteosource_response_data['daily']['data'][0]['summary']\n",
        "  print(weather_forecast)\n",
        "\n",
        "else:\n",
        "  print(meteosource_response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiFOB7uU1f3b",
        "outputId": "389655c5-e03d-437c-fb94-634600774f79"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partly sunny, fewer clouds in the afternoon. Temperature 5/18 °C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Chat GPT Prompt"
      ],
      "metadata": {
        "id": "frn5NHOiOKUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the ChatGPT prompt to write a daily update\n",
        "developer_message = '''\n",
        "You are an AI assistant that sends a morning newsletter with the main news of\n",
        "the day and the weather. You provide an enjoyable an easy-to-read text to\n",
        "accompany user on their morning coffee. The update should be about 2-5 minutes\n",
        "long, incorporating both the weather forecast and the top 10 headlines in a way\n",
        "that feels conversational, lively and fits a specific tone (such as funny,\n",
        "serious, sarcastic or motivational). You have to speak in Castillian Spanish\n",
        "as it would be spoken in the country of Spain. For example, they do not use the\n",
        "third person when talking to strangers, so you should use the second person. You\n",
        "have to speak in Spain and try to sound natural in that language, even if the\n",
        "information that you receive is written in english. Do not output anything else\n",
        "than the text. The text will be sent to a text-to-speech api to generate an MP3,\n",
        "so make sure the output does not contain something that should not be read out\n",
        "loud.\n",
        "\n",
        "Structure the monologue as follows:\n",
        "\n",
        "1. Greeting: Start with a warm and welcoming greeting.\n",
        "2. Weather Summary: Describe the day's weather, infusing the chosen tone to\n",
        "make it engaging.\n",
        "3. News Headlines: Present each headline in the chosen tone, followed with a\n",
        "summary of the headline to give the user a deeper insight into the headline.\n",
        "4. Closing: Wrap up with a concluding remark that leaves the user with a smile,\n",
        "positive thought or playful nudge.\n",
        "\n",
        "Be creative in how you incorporate the tone and style, ensuring that the text\n",
        "is engaging and enjoyable to listen to.\n",
        "'''\n",
        "\n",
        "user_message = f'''\n",
        "Please generate a 'Morning update' text in a funny and light tone.\n",
        "\n",
        "Here is the Weater Forecast:\n",
        "{weather_forecast}\n",
        "\n",
        "Here are the News Headlines in JSON format:\n",
        "{headline_articles}\n",
        "\n",
        "Generate the text as specified in the system prompt, in spanish, following the\n",
        "structure of greeting, weather summary, news headlines and closing remark.\n",
        "'''"
      ],
      "metadata": {
        "id": "_CBA9l6X6Kp8"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set OpenAI api parameters for the request\n",
        "openai_headers = {\n",
        "    'Authorization': f'Bearer {API_KEY_OPENAI}'\n",
        "}\n",
        "\n",
        "openai_request_parameters = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"developer\", \"content\": developer_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "pk1dkKXIDYN9"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the morning newsletter from OpenAi API\n",
        "openai_response = requests.post('https://api.openai.com/v1/chat/completions',\n",
        "                         headers = openai_headers,\n",
        "                         json = openai_request_parameters)\n",
        "\n",
        "if openai_response.status_code == 200:\n",
        "  openai_response_data = openai_response.json()\n",
        "\n",
        "else:\n",
        "  print(openai_response.text)"
      ],
      "metadata": {
        "id": "cxhtcC6JGUOo"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_response_text = openai_response_data['choices'][0]['message']['content']\n",
        "print(openai_response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbk-W_ywHWAv",
        "outputId": "924deb42-7455-4303-c455-2fa3af70b38f"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Buenos días, querido oyente! Espero que estés listo para comenzar el día con una dosis de risas y noticias frescas, como un café bien cargado por la mañana. \n",
            "\n",
            "Primero, hablemos del clima. Hoy es uno de esos días en los que el sol se esfuerza por salir y las nubes deciden quedarse un ratito más en la cama. Tendremos temperaturas que van de los 5 a los 18 grados, así que asegúrate de vestirte en capas, para que no acabes con el sudor de un maratonista en pleno verano en pleno invierno. \n",
            "\n",
            "Ahora, vamos con las novedades del día, que están más interesantes que ese gato que se ha hecho viral en internet:\n",
            "\n",
            "1. **¿Un escenario de pesadilla?** Los incendios en Los Ángeles están quemando más que solo árboles; también están avivando una crisis de seguros. Parece que el clima y la economía californiana decidieron hacer un cóctel explosivo, justo cuando empezaban a hacer reformas. ¡Menuda fiesta!\n",
            "\n",
            "2. **Jean Smart lanza un grito al cielo:** La actriz ha pedido a las cadenas de televisión que no transmitan las entregas de premios de Hollywood mientras Los Ángeles arde. No sé tú, pero yo preferiría ver a los gatos en el internet que a un desfile de estrellas cuando el fuego está ahí fuera.\n",
            "\n",
            "3. **¡Algo más que sushi!** Un supuesto líder de la Yakuza ha admitido haber traficado materiales nucleares desde Myanmar. Esto suena más a una película de acción que a la realidad, pero aquí estamos, amigos.\n",
            "\n",
            "4. **Garland pide permiso:** El fiscal general está buscando liberar su informe del 6 de enero antes de que Trump vuelva a ocupar un cargo. Quizás una vez liberado el informe, podríamos entender mejor esa \"mejor forma de gobernar\" de Twitter.\n",
            "\n",
            "5. **Un Android por 200 dólares:** TCL ha presentado un smartphone en CES que, según dicen, es el único que deberías considerar, así que guarda ese dinero para no comprar cosas innecesarias (como un abridor de latas inteligente, que a nadie le hace falta).\n",
            "\n",
            "6. **Actualizaciones de incendios en California:** Las cosas están muy serias con los incendios en Hollywood Hills; se reportan 5 muertos y las autoridades advierten que los vientos podrían seguir avivando el fuego. Así que, por el amor de todo lo sagrado, mantente alejado de las hogueras.\n",
            "\n",
            "7. **Jim Jarmusch y su cruzada:** El director no se ha mordido la lengua y ha criticado a los negacionistas del clima mientras otros actores envían \"corazones\" y \"oraciones\" a Los Ángeles desde Nueva York. Es como si el amor pudiera apagar el fuego. \n",
            "\n",
            "8. **Musk y los datos de IA:** Elon Musk ha reconocido que estamos con los datos de inteligencia artificial en un callejón sin salida. Quizás deberíamos empezar a hablarles en español, a ver si entienden algo.\n",
            "\n",
            "9. **Huelga en puertos evitada:** Una huelga masiva de estibadores fue evitada gracias a un acuerdo tentativo. Al final, todos seguirán trabajando y evitando que la economía se convierta en un Titanic. \n",
            "\n",
            "10. **Musk y la ley de la UE:** En Bruselas no se andan con tonterías y están observando de cerca a Musk para ver si se salta las leyes europeas en un livestream. Ya sabes, ¡no hay nada como un poco de vigilancia para mantenerlo interesante!\n",
            "\n",
            "Y así, con el ajetreo y bullicio del mundo, espero que tu café esté sabroso y que tengas un día tan brillante como el sol que intenta asomarse. Recuerda, siempre hay luz al final del túnel, a no ser que haya un incendio en medio. ¡Que tengas un día fabuloso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to speech using OpenAi AI\n",
        "openai_audio_parameters = {\n",
        "    \"model\": \"tts-1\",\n",
        "    \"voice\": \"alloy\",\n",
        "    \"input\": openai_response_text,\n",
        "}\n",
        "\n",
        "openai_response = requests.post('https://api.openai.com/v1/audio/speech',\n",
        "                         headers = openai_headers,\n",
        "                         json = openai_audio_parameters)\n",
        "\n",
        "if openai_response.status_code == 200:\n",
        "  speech_file = open(\"morning_update.mp3\", \"wb\")\n",
        "  speech_file.write(openai_response.content)\n",
        "  speech_file.close()\n",
        "\n",
        "else:\n",
        "  print(openai_response.text)"
      ],
      "metadata": {
        "id": "gj5tLX9iablx"
      },
      "execution_count": 131,
      "outputs": []
    }
  ]
}